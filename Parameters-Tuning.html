<!DOCTYPE html>
<html class="writer-html5" lang="en" >
<head>
  <meta charset="utf-8" /><meta name="generator" content="Docutils 0.18.1: http://docutils.sourceforge.net/" />

  <meta name="viewport" content="width=device-width, initial-scale=1.0" />
  <title>Parameters Tuning &mdash; LightGBM 3.3.5.99 documentation</title>
      <link rel="stylesheet" href="_static/pygments.css" type="text/css" />
      <link rel="stylesheet" href="_static/css/theme.css" type="text/css" />
    <link rel="shortcut icon" href="_static/favicon.ico"/>
  <!--[if lt IE 9]>
    <script src="_static/js/html5shiv.min.js"></script>
  <![endif]-->
  
        <script data-url_root="./" id="documentation_options" src="_static/documentation_options.js"></script>
        <script src="_static/jquery.js"></script>
        <script src="_static/underscore.js"></script>
        <script src="_static/_sphinx_javascript_frameworks_compat.js"></script>
        <script src="_static/doctools.js"></script>
        <script src="_static/sphinx_highlight.js"></script>
        <script src="_static/js/script.js"></script>
    <script src="_static/js/theme.js"></script>
    <link rel="index" title="Index" href="genindex.html" />
    <link rel="search" title="Search" href="search.html" />
    <link rel="next" title="C API" href="C-API.html" />
    <link rel="prev" title="Parameters" href="Parameters.html" /> 
</head>

<body class="wy-body-for-nav"> 
  <div class="wy-grid-for-nav">
    <nav data-toggle="wy-nav-shift" class="wy-nav-side">
      <div class="wy-side-scroll">
        <div class="wy-side-nav-search" >

          
          
          <a href="index.html">
            
              <img src="_static/LightGBM_logo_grey_text.svg" class="logo" alt="Logo"/>
          </a>
              <div class="version">
                3.3.5.99
              </div>
<div role="search">
  <form id="rtd-search-form" class="wy-form" action="search.html" method="get">
    <input type="text" name="q" placeholder="Search docs" aria-label="Search docs" />
    <input type="hidden" name="check_keywords" value="yes" />
    <input type="hidden" name="area" value="default" />
  </form>
</div>
        </div><div class="wy-menu wy-menu-vertical" data-spy="affix" role="navigation" aria-label="Navigation menu">
              <p class="caption" role="heading"><span class="caption-text">Contents:</span></p>
<ul class="current">
<li class="toctree-l1"><a class="reference internal" href="Installation-Guide.html">Installation Guide</a></li>
<li class="toctree-l1"><a class="reference internal" href="Quick-Start.html">Quick Start</a></li>
<li class="toctree-l1"><a class="reference internal" href="Python-Intro.html">Python Quick Start</a></li>
<li class="toctree-l1"><a class="reference internal" href="Features.html">Features</a></li>
<li class="toctree-l1"><a class="reference internal" href="Experiments.html">Experiments</a></li>
<li class="toctree-l1"><a class="reference internal" href="Parameters.html">Parameters</a></li>
<li class="toctree-l1 current"><a class="current reference internal" href="#">Parameters Tuning</a><ul>
<li class="toctree-l2"><a class="reference internal" href="#tune-parameters-for-the-leaf-wise-best-first-tree">Tune Parameters for the Leaf-wise (Best-first) Tree</a></li>
<li class="toctree-l2"><a class="reference internal" href="#for-faster-speed">For Faster Speed</a><ul>
<li class="toctree-l3"><a class="reference internal" href="#add-more-computational-resources">Add More Computational Resources</a></li>
<li class="toctree-l3"><a class="reference internal" href="#use-a-gpu-enabled-version-of-lightgbm">Use a GPU-enabled version of LightGBM</a></li>
<li class="toctree-l3"><a class="reference internal" href="#grow-shallower-trees">Grow Shallower Trees</a><ul>
<li class="toctree-l4"><a class="reference internal" href="#decrease-max-depth">Decrease <code class="docutils literal notranslate"><span class="pre">max_depth</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="#decrease-num-leaves">Decrease <code class="docutils literal notranslate"><span class="pre">num_leaves</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="#increase-min-gain-to-split">Increase <code class="docutils literal notranslate"><span class="pre">min_gain_to_split</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="#increase-min-data-in-leaf-and-min-sum-hessian-in-leaf">Increase <code class="docutils literal notranslate"><span class="pre">min_data_in_leaf</span></code> and <code class="docutils literal notranslate"><span class="pre">min_sum_hessian_in_leaf</span></code></a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="#grow-less-trees">Grow Less Trees</a><ul>
<li class="toctree-l4"><a class="reference internal" href="#decrease-num-iterations">Decrease <code class="docutils literal notranslate"><span class="pre">num_iterations</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="#use-early-stopping">Use Early Stopping</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="#consider-fewer-splits">Consider Fewer Splits</a><ul>
<li class="toctree-l4"><a class="reference internal" href="#enable-feature-pre-filtering-when-creating-dataset">Enable Feature Pre-Filtering When Creating Dataset</a></li>
<li class="toctree-l4"><a class="reference internal" href="#decrease-max-bin-or-max-bin-by-feature-when-creating-dataset">Decrease <code class="docutils literal notranslate"><span class="pre">max_bin</span></code> or <code class="docutils literal notranslate"><span class="pre">max_bin_by_feature</span></code> When Creating Dataset</a></li>
<li class="toctree-l4"><a class="reference internal" href="#increase-min-data-in-bin-when-creating-dataset">Increase <code class="docutils literal notranslate"><span class="pre">min_data_in_bin</span></code> When Creating Dataset</a></li>
<li class="toctree-l4"><a class="reference internal" href="#decrease-feature-fraction">Decrease <code class="docutils literal notranslate"><span class="pre">feature_fraction</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="#decrease-max-cat-threshold">Decrease <code class="docutils literal notranslate"><span class="pre">max_cat_threshold</span></code></a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="#use-less-data">Use Less Data</a><ul>
<li class="toctree-l4"><a class="reference internal" href="#use-bagging">Use Bagging</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="#save-constructed-datasets-with-save-binary">Save Constructed Datasets with <code class="docutils literal notranslate"><span class="pre">save_binary</span></code></a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="#for-better-accuracy">For Better Accuracy</a></li>
<li class="toctree-l2"><a class="reference internal" href="#deal-with-over-fitting">Deal with Over-fitting</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="C-API.html">C API</a></li>
<li class="toctree-l1"><a class="reference internal" href="Python-API.html">Python API</a></li>
<li class="toctree-l1"><a class="reference external" href="https://lightgbm.readthedocs.io/en/latest/R/reference/">R API</a></li>
<li class="toctree-l1"><a class="reference internal" href="Parallel-Learning-Guide.html">Distributed Learning Guide</a></li>
<li class="toctree-l1"><a class="reference internal" href="GPU-Tutorial.html">GPU Tutorial</a></li>
<li class="toctree-l1"><a class="reference internal" href="Advanced-Topics.html">Advanced Topics</a></li>
<li class="toctree-l1"><a class="reference internal" href="FAQ.html">FAQ</a></li>
<li class="toctree-l1"><a class="reference internal" href="Development-Guide.html">Development Guide</a></li>
</ul>

        </div>
      </div>
    </nav>

    <section data-toggle="wy-nav-shift" class="wy-nav-content-wrap"><nav class="wy-nav-top" aria-label="Mobile navigation menu" >
          <i data-toggle="wy-nav-top" class="fa fa-bars"></i>
          <a href="index.html">LightGBM</a>
      </nav>

      <div class="wy-nav-content">
        <div class="rst-content">
          <div role="navigation" aria-label="Page navigation">
  <ul class="wy-breadcrumbs">
      <li><a href="index.html" class="icon icon-home" aria-label="Home"></a></li>
      <li class="breadcrumb-item active">Parameters Tuning</li>
      <li class="wy-breadcrumbs-aside">
            <a href="_sources/Parameters-Tuning.rst.txt" rel="nofollow"> View page source</a>
      </li>
  </ul>
  <hr/>
</div>
          <div role="main" class="document" itemscope="itemscope" itemtype="http://schema.org/Article">
           <div itemprop="articleBody">
             
  <section id="parameters-tuning">
<h1>Parameters Tuning<a class="headerlink" href="#parameters-tuning" title="Permalink to this heading"></a></h1>
<p>This page contains parameters tuning guides for different scenarios.</p>
<p><strong>List of other helpful links</strong></p>
<ul class="simple">
<li><p><a class="reference external" href="./Parameters.html">Parameters</a></p></li>
<li><p><a class="reference external" href="./Python-API.html">Python API</a></p></li>
<li><p><a class="reference external" href="https://github.com/microsoft/FLAML">FLAML</a> for automated hyperparameter tuning</p></li>
<li><p><a class="reference external" href="https://medium.com/optuna/lightgbm-tuner-new-optuna-integration-for-hyperparameter-optimization-8b7095e99258">Optuna</a> for automated hyperparameter tuning</p></li>
</ul>
<section id="tune-parameters-for-the-leaf-wise-best-first-tree">
<h2>Tune Parameters for the Leaf-wise (Best-first) Tree<a class="headerlink" href="#tune-parameters-for-the-leaf-wise-best-first-tree" title="Permalink to this heading"></a></h2>
<p>LightGBM uses the <a class="reference external" href="./Features.html#leaf-wise-best-first-tree-growth">leaf-wise</a> tree growth algorithm, while many other popular tools use depth-wise tree growth.
Compared with depth-wise growth, the leaf-wise algorithm can converge much faster.
However, the leaf-wise growth may be over-fitting if not used with the appropriate parameters.</p>
<p>To get good results using a leaf-wise tree, these are some important parameters:</p>
<ol class="arabic simple">
<li><p><code class="docutils literal notranslate"><span class="pre">num_leaves</span></code>. This is the main parameter to control the complexity of the tree model.
Theoretically, we can set <code class="docutils literal notranslate"><span class="pre">num_leaves</span> <span class="pre">=</span> <span class="pre">2^(max_depth)</span></code> to obtain the same number of leaves as depth-wise tree.
However, this simple conversion is not good in practice.
The reason is that a leaf-wise tree is typically much deeper than a depth-wise tree for a fixed number of leaves. Unconstrained depth can induce over-fitting.
Thus, when trying to tune the <code class="docutils literal notranslate"><span class="pre">num_leaves</span></code>, we should let it be smaller than <code class="docutils literal notranslate"><span class="pre">2^(max_depth)</span></code>.
For example, when the <code class="docutils literal notranslate"><span class="pre">max_depth=7</span></code> the depth-wise tree can get good accuracy,
but setting <code class="docutils literal notranslate"><span class="pre">num_leaves</span></code> to <code class="docutils literal notranslate"><span class="pre">127</span></code> may cause over-fitting, and setting it to <code class="docutils literal notranslate"><span class="pre">70</span></code> or <code class="docutils literal notranslate"><span class="pre">80</span></code> may get better accuracy than depth-wise.</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">min_data_in_leaf</span></code>. This is a very important parameter to prevent over-fitting in a leaf-wise tree.
Its optimal value depends on the number of training samples and <code class="docutils literal notranslate"><span class="pre">num_leaves</span></code>.
Setting it to a large value can avoid growing too deep a tree, but may cause under-fitting.
In practice, setting it to hundreds or thousands is enough for a large dataset.</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">max_depth</span></code>. You also can use <code class="docutils literal notranslate"><span class="pre">max_depth</span></code> to limit the tree depth explicitly.</p></li>
</ol>
</section>
<section id="for-faster-speed">
<h2>For Faster Speed<a class="headerlink" href="#for-faster-speed" title="Permalink to this heading"></a></h2>
<section id="add-more-computational-resources">
<h3>Add More Computational Resources<a class="headerlink" href="#add-more-computational-resources" title="Permalink to this heading"></a></h3>
<p>On systems where it is available, LightGBM uses OpenMP to parallelize many operations. The maximum number of threads used by LightGBM is controlled by the parameter <code class="docutils literal notranslate"><span class="pre">num_threads</span></code>. By default, this will defer to the default behavior of OpenMP (one thread per real CPU core or the value in environment variable <code class="docutils literal notranslate"><span class="pre">OMP_NUM_THREADS</span></code>, if it is set). For best performance, set this to the number of <strong>real</strong> CPU cores available.</p>
<p>You might be able to achieve faster training by moving to a machine with more available CPU cores.</p>
<p>Using distributed (multi-machine) training might also reduce training time. See the <a class="reference external" href="./Parallel-Learning-Guide.html">Distributed Learning Guide</a> for details.</p>
</section>
<section id="use-a-gpu-enabled-version-of-lightgbm">
<h3>Use a GPU-enabled version of LightGBM<a class="headerlink" href="#use-a-gpu-enabled-version-of-lightgbm" title="Permalink to this heading"></a></h3>
<p>You might find that training is faster using a GPU-enabled build of LightGBM. See the <a class="reference external" href="./GPU-Tutorial.html">GPU Tutorial</a> for details.</p>
</section>
<section id="grow-shallower-trees">
<h3>Grow Shallower Trees<a class="headerlink" href="#grow-shallower-trees" title="Permalink to this heading"></a></h3>
<p>The total training time for LightGBM increases with the total number of tree nodes added. LightGBM comes with several parameters that can be used to control the number of nodes per tree.</p>
<p>The suggestions below will speed up training, but might hurt training accuracy.</p>
<section id="decrease-max-depth">
<h4>Decrease <code class="docutils literal notranslate"><span class="pre">max_depth</span></code><a class="headerlink" href="#decrease-max-depth" title="Permalink to this heading"></a></h4>
<p>This parameter is an integer that controls the maximum distance between the root node of each tree and a leaf node. Decrease <code class="docutils literal notranslate"><span class="pre">max_depth</span></code> to reduce training time.</p>
</section>
<section id="decrease-num-leaves">
<h4>Decrease <code class="docutils literal notranslate"><span class="pre">num_leaves</span></code><a class="headerlink" href="#decrease-num-leaves" title="Permalink to this heading"></a></h4>
<p>LightGBM adds nodes to trees based on the gain from adding that node, regardless of depth. This figure from <a class="reference external" href="./Features.html#leaf-wise-best-first-tree-growth">the feature documentation</a> illustrates the process.</p>
<img alt="Three consecutive images of decision trees, where each shows the tree with an additional two leaf nodes added. Shows that leaf-wise growth can result in trees that have some branches which are longer than others." class="align-center" src="_images/leaf-wise.png" />
<p>Because of this growth strategy, it isn’t straightforward to use <code class="docutils literal notranslate"><span class="pre">max_depth</span></code> alone to limit the complexity of trees. The <code class="docutils literal notranslate"><span class="pre">num_leaves</span></code> parameter sets the maximum number of nodes per tree. Decrease <code class="docutils literal notranslate"><span class="pre">num_leaves</span></code> to reduce training time.</p>
</section>
<section id="increase-min-gain-to-split">
<h4>Increase <code class="docutils literal notranslate"><span class="pre">min_gain_to_split</span></code><a class="headerlink" href="#increase-min-gain-to-split" title="Permalink to this heading"></a></h4>
<p>When adding a new tree node, LightGBM chooses the split point that has the largest gain. Gain is basically the reduction in training loss that results from adding a split point. By default, LightGBM sets <code class="docutils literal notranslate"><span class="pre">min_gain_to_split</span></code> to 0.0, which means “there is no improvement that is too small”. However, in practice you might find that very small improvements in the training loss don’t have a meaningful impact on the generalization error of the model. Increase <code class="docutils literal notranslate"><span class="pre">min_gain_to_split</span></code> to reduce training time.</p>
</section>
<section id="increase-min-data-in-leaf-and-min-sum-hessian-in-leaf">
<h4>Increase <code class="docutils literal notranslate"><span class="pre">min_data_in_leaf</span></code> and <code class="docutils literal notranslate"><span class="pre">min_sum_hessian_in_leaf</span></code><a class="headerlink" href="#increase-min-data-in-leaf-and-min-sum-hessian-in-leaf" title="Permalink to this heading"></a></h4>
<p>Depending on the size of the training data and the distribution of features, it’s possible for LightGBM to add tree nodes that only describe a small number of observations. In the most extreme case, consider the addition of a tree node that only a single observation from the training data falls into. This is very unlikely to generalize well, and probably is a sign of overfitting.</p>
<p>This can be prevented indirectly with parameters like <code class="docutils literal notranslate"><span class="pre">max_depth</span></code> and <code class="docutils literal notranslate"><span class="pre">num_leaves</span></code>, but LightGBM also offers parameters to help you directly avoid adding these overly-specific tree nodes.</p>
<ul class="simple">
<li><p><code class="docutils literal notranslate"><span class="pre">min_data_in_leaf</span></code>: Minimum number of observations that must fall into a tree node for it to be added.</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">min_sum_hessian_in_leaf</span></code>: Minimum sum of the Hessian (second derivative of the objective function evaluated for each observation) for observations in a leaf. For some regression objectives, this is just the minimum number of records that have to fall into each node. For classification objectives, it represents a sum over a distribution of probabilities. See <a class="reference external" href="https://stats.stackexchange.com/questions/317073/explanation-of-min-child-weight-in-xgboost-algorithm">this Stack Overflow answer</a> for a good description of how to reason about values of this parameter.</p></li>
</ul>
</section>
</section>
<section id="grow-less-trees">
<h3>Grow Less Trees<a class="headerlink" href="#grow-less-trees" title="Permalink to this heading"></a></h3>
<section id="decrease-num-iterations">
<h4>Decrease <code class="docutils literal notranslate"><span class="pre">num_iterations</span></code><a class="headerlink" href="#decrease-num-iterations" title="Permalink to this heading"></a></h4>
<p>The <code class="docutils literal notranslate"><span class="pre">num_iterations</span></code> parameter controls the number of boosting rounds that will be performed. Since LightGBM uses decision trees as the learners, this can also be thought of as “number of trees”.</p>
<p>If you try changing <code class="docutils literal notranslate"><span class="pre">num_iterations</span></code>, change the <code class="docutils literal notranslate"><span class="pre">learning_rate</span></code> as well. <code class="docutils literal notranslate"><span class="pre">learning_rate</span></code> will not have any impact on training time, but it will impact the training accuracy. As a general rule, if you reduce <code class="docutils literal notranslate"><span class="pre">num_iterations</span></code>, you should increase <code class="docutils literal notranslate"><span class="pre">learning_rate</span></code>.</p>
<p>Choosing the right value of <code class="docutils literal notranslate"><span class="pre">num_iterations</span></code> and <code class="docutils literal notranslate"><span class="pre">learning_rate</span></code> is highly dependent on the data and objective, so these parameters are often chosen from a set of possible values through hyperparameter tuning.</p>
<p>Decrease <code class="docutils literal notranslate"><span class="pre">num_iterations</span></code> to reduce training time.</p>
</section>
<section id="use-early-stopping">
<h4>Use Early Stopping<a class="headerlink" href="#use-early-stopping" title="Permalink to this heading"></a></h4>
<p>If early stopping is enabled, after each boosting round the model’s training accuracy is evaluated against a validation set that contains data not available to the training process. That accuracy is then compared to the accuracy as of the previous boosting round. If the model’s accuracy fails to improve for some number of consecutive rounds, LightGBM stops the training process.</p>
<p>That “number of consecutive rounds” is controlled by the parameter <code class="docutils literal notranslate"><span class="pre">early_stopping_round</span></code>. For example, <code class="docutils literal notranslate"><span class="pre">early_stopping_round=1</span></code> says “the first time accuracy on the validation set does not improve, stop training”.</p>
<p>Set <code class="docutils literal notranslate"><span class="pre">early_stopping_round</span></code> and provide a validation set to possibly reduce training time.</p>
</section>
</section>
<section id="consider-fewer-splits">
<h3>Consider Fewer Splits<a class="headerlink" href="#consider-fewer-splits" title="Permalink to this heading"></a></h3>
<p>The parameters described in previous sections control how many trees are constructed and how many nodes are constructed per tree. Training time can be further reduced by reducing the amount of time needed to add a tree node to the model.</p>
<p>The suggestions below will speed up training, but might hurt training accuracy.</p>
<section id="enable-feature-pre-filtering-when-creating-dataset">
<h4>Enable Feature Pre-Filtering When Creating Dataset<a class="headerlink" href="#enable-feature-pre-filtering-when-creating-dataset" title="Permalink to this heading"></a></h4>
<p>By default, when a LightGBM <code class="docutils literal notranslate"><span class="pre">Dataset</span></code> object is constructed, some features will be filtered out based on the value of <code class="docutils literal notranslate"><span class="pre">min_data_in_leaf</span></code>.</p>
<p>For a simple example, consider a 1000-observation dataset with a feature called <code class="docutils literal notranslate"><span class="pre">feature_1</span></code>. <code class="docutils literal notranslate"><span class="pre">feature_1</span></code> takes on only two values: 25.0 (995 observations) and 50.0 (5 observations). If <code class="docutils literal notranslate"><span class="pre">min_data_in_leaf</span> <span class="pre">=</span> <span class="pre">10</span></code>, there is no split for this feature which will result in a valid split at least one of the leaf nodes will only have 5 observations.</p>
<p>Instead of reconsidering this feature and then ignoring it every iteration, LightGBM filters this feature out at before training, when the <code class="docutils literal notranslate"><span class="pre">Dataset</span></code> is constructed.</p>
<p>If this default behavior has been overridden by setting <code class="docutils literal notranslate"><span class="pre">feature_pre_filter=False</span></code>, set <code class="docutils literal notranslate"><span class="pre">feature_pre_filter=True</span></code> to reduce training time.</p>
</section>
<section id="decrease-max-bin-or-max-bin-by-feature-when-creating-dataset">
<h4>Decrease <code class="docutils literal notranslate"><span class="pre">max_bin</span></code> or <code class="docutils literal notranslate"><span class="pre">max_bin_by_feature</span></code> When Creating Dataset<a class="headerlink" href="#decrease-max-bin-or-max-bin-by-feature-when-creating-dataset" title="Permalink to this heading"></a></h4>
<p>LightGBM training <a class="reference external" href="./Features.html#optimization-in-speed-and-memory-usage">buckets continuous features into discrete bins</a> to improve training speed and reduce memory requirements for training. This binning is done one time during <code class="docutils literal notranslate"><span class="pre">Dataset</span></code> construction. The number of splits considered when adding a node is <code class="docutils literal notranslate"><span class="pre">O(#feature</span> <span class="pre">*</span> <span class="pre">#bin)</span></code>, so reducing the number of bins per feature can reduce the number of splits that need to be evaluated.</p>
<p><code class="docutils literal notranslate"><span class="pre">max_bin</span></code> is controls the maximum number of bins that features will bucketed into. It is also possible to set this maximum feature-by-feature, by passing <code class="docutils literal notranslate"><span class="pre">max_bin_by_feature</span></code>.</p>
<p>Reduce <code class="docutils literal notranslate"><span class="pre">max_bin</span></code> or <code class="docutils literal notranslate"><span class="pre">max_bin_by_feature</span></code> to reduce training time.</p>
</section>
<section id="increase-min-data-in-bin-when-creating-dataset">
<h4>Increase <code class="docutils literal notranslate"><span class="pre">min_data_in_bin</span></code> When Creating Dataset<a class="headerlink" href="#increase-min-data-in-bin-when-creating-dataset" title="Permalink to this heading"></a></h4>
<p>Some bins might contain a small number of observations, which might mean that the effort of evaluating that bin’s boundaries as possible split points isn’t likely to change the final model very much. You can control the granularity of the bins by setting <code class="docutils literal notranslate"><span class="pre">min_data_in_bin</span></code>.</p>
<p>Increase <code class="docutils literal notranslate"><span class="pre">min_data_in_bin</span></code> to reduce training time.</p>
</section>
<section id="decrease-feature-fraction">
<h4>Decrease <code class="docutils literal notranslate"><span class="pre">feature_fraction</span></code><a class="headerlink" href="#decrease-feature-fraction" title="Permalink to this heading"></a></h4>
<p>By default, LightGBM considers all features in a <code class="docutils literal notranslate"><span class="pre">Dataset</span></code> during the training process. This behavior can be changed by setting <code class="docutils literal notranslate"><span class="pre">feature_fraction</span></code> to a value <code class="docutils literal notranslate"><span class="pre">&gt;</span> <span class="pre">0</span></code> and <code class="docutils literal notranslate"><span class="pre">&lt;=</span> <span class="pre">1.0</span></code>. Setting <code class="docutils literal notranslate"><span class="pre">feature_fraction</span></code> to <code class="docutils literal notranslate"><span class="pre">0.5</span></code>, for example, tells LightGBM to randomly select <code class="docutils literal notranslate"><span class="pre">50%</span></code> of features at the beginning of constructing each tree. This reduces the total number of splits that have to be evaluated to add each tree node.</p>
<p>Decrease <code class="docutils literal notranslate"><span class="pre">feature_fraction</span></code> to reduce training time.</p>
</section>
<section id="decrease-max-cat-threshold">
<h4>Decrease <code class="docutils literal notranslate"><span class="pre">max_cat_threshold</span></code><a class="headerlink" href="#decrease-max-cat-threshold" title="Permalink to this heading"></a></h4>
<p>LightGBM uses a <a class="reference external" href="./Advanced-Topics.html#categorical-feature-support">custom approach for finding optimal splits for categorical features</a>. In this process, LightGBM explores splits that break a categorical feature into two groups. These are sometimes called “k-vs.-rest” splits. Higher <code class="docutils literal notranslate"><span class="pre">max_cat_threshold</span></code> values correspond to more split points and larger possible group sizes to search.</p>
<p>Decrease <code class="docutils literal notranslate"><span class="pre">max_cat_threshold</span></code> to reduce training time.</p>
</section>
</section>
<section id="use-less-data">
<h3>Use Less Data<a class="headerlink" href="#use-less-data" title="Permalink to this heading"></a></h3>
<section id="use-bagging">
<h4>Use Bagging<a class="headerlink" href="#use-bagging" title="Permalink to this heading"></a></h4>
<p>By default, LightGBM uses all observations in the training data for each iteration. It is possible to instead tell LightGBM to randomly sample the training data. This process of training over multiple random samples without replacement is called “bagging”.</p>
<p>Set <code class="docutils literal notranslate"><span class="pre">bagging_freq</span></code> to an integer greater than 0 to control how often a new sample is drawn. Set <code class="docutils literal notranslate"><span class="pre">bagging_fraction</span></code> to a value <code class="docutils literal notranslate"><span class="pre">&gt;</span> <span class="pre">0.0</span></code> and <code class="docutils literal notranslate"><span class="pre">&lt;</span> <span class="pre">1.0</span></code> to control the size of the sample. For example, <code class="docutils literal notranslate"><span class="pre">{&quot;bagging_freq&quot;:</span> <span class="pre">5,</span> <span class="pre">&quot;bagging_fraction&quot;:</span> <span class="pre">0.75}</span></code> tells LightGBM “re-sample without replacement every 5 iterations, and draw samples of 75% of the training data”.</p>
<p>Decrease <code class="docutils literal notranslate"><span class="pre">bagging_fraction</span></code> to reduce training time.</p>
</section>
</section>
<section id="save-constructed-datasets-with-save-binary">
<h3>Save Constructed Datasets with <code class="docutils literal notranslate"><span class="pre">save_binary</span></code><a class="headerlink" href="#save-constructed-datasets-with-save-binary" title="Permalink to this heading"></a></h3>
<p>This only applies to the LightGBM CLI. If you pass parameter <code class="docutils literal notranslate"><span class="pre">save_binary</span></code>, the training dataset and all validations sets will be saved in a binary format understood by LightGBM. This can speed up training next time, because binning and other work done when constructing a <code class="docutils literal notranslate"><span class="pre">Dataset</span></code> does not have to be re-done.</p>
</section>
</section>
<section id="for-better-accuracy">
<h2>For Better Accuracy<a class="headerlink" href="#for-better-accuracy" title="Permalink to this heading"></a></h2>
<ul class="simple">
<li><p>Use large <code class="docutils literal notranslate"><span class="pre">max_bin</span></code> (may be slower)</p></li>
<li><p>Use small <code class="docutils literal notranslate"><span class="pre">learning_rate</span></code> with large <code class="docutils literal notranslate"><span class="pre">num_iterations</span></code></p></li>
<li><p>Use large <code class="docutils literal notranslate"><span class="pre">num_leaves</span></code> (may cause over-fitting)</p></li>
<li><p>Use bigger training data</p></li>
<li><p>Try <code class="docutils literal notranslate"><span class="pre">dart</span></code></p></li>
</ul>
</section>
<section id="deal-with-over-fitting">
<h2>Deal with Over-fitting<a class="headerlink" href="#deal-with-over-fitting" title="Permalink to this heading"></a></h2>
<ul class="simple">
<li><p>Use small <code class="docutils literal notranslate"><span class="pre">max_bin</span></code></p></li>
<li><p>Use small <code class="docutils literal notranslate"><span class="pre">num_leaves</span></code></p></li>
<li><p>Use <code class="docutils literal notranslate"><span class="pre">min_data_in_leaf</span></code> and <code class="docutils literal notranslate"><span class="pre">min_sum_hessian_in_leaf</span></code></p></li>
<li><p>Use bagging by set <code class="docutils literal notranslate"><span class="pre">bagging_fraction</span></code> and <code class="docutils literal notranslate"><span class="pre">bagging_freq</span></code></p></li>
<li><p>Use feature sub-sampling by set <code class="docutils literal notranslate"><span class="pre">feature_fraction</span></code></p></li>
<li><p>Use bigger training data</p></li>
<li><p>Try <code class="docutils literal notranslate"><span class="pre">lambda_l1</span></code>, <code class="docutils literal notranslate"><span class="pre">lambda_l2</span></code> and <code class="docutils literal notranslate"><span class="pre">min_gain_to_split</span></code> for regularization</p></li>
<li><p>Try <code class="docutils literal notranslate"><span class="pre">max_depth</span></code> to avoid growing deep tree</p></li>
<li><p>Try <code class="docutils literal notranslate"><span class="pre">extra_trees</span></code></p></li>
<li><p>Try increasing <code class="docutils literal notranslate"><span class="pre">path_smooth</span></code></p></li>
</ul>
</section>
</section>


           </div>
          </div>
          <footer><div class="rst-footer-buttons" role="navigation" aria-label="Footer">
        <a href="Parameters.html" class="btn btn-neutral float-left" title="Parameters" accesskey="p" rel="prev"><span class="fa fa-arrow-circle-left" aria-hidden="true"></span> Previous</a>
        <a href="C-API.html" class="btn btn-neutral float-right" title="C API" accesskey="n" rel="next">Next <span class="fa fa-arrow-circle-right" aria-hidden="true"></span></a>
    </div>

  <hr/>

  <div role="contentinfo">
    <p>&#169; Copyright 2023, Microsoft Corporation.</p>
  </div>

  Built with <a href="https://www.sphinx-doc.org/">Sphinx</a> using a
    <a href="https://github.com/readthedocs/sphinx_rtd_theme">theme</a>
    provided by <a href="https://readthedocs.org">Read the Docs</a>.
   

</footer>
        </div>
      </div>
    </section>
  </div>
  <script>
      jQuery(function () {
          SphinxRtdTheme.Navigation.enable(true);
      });
  </script> 

</body>
</html>